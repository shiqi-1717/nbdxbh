import base64
import io
import json
import zipfile
from pathlib import Path
from typing import List

import numpy as np
import pandas as pd
import requests
import streamlit as st
from PIL import Image
from websocket import create_connection, WebSocket
from ultralytics import YOLO

# å¯é€‰å¯¼å…¥ OpenCVï¼ˆäº‘ç«¯æ²¡æœ‰ GUIï¼Œç”¨ headless è½®å­å³å¯ï¼›å¤±è´¥æ—¶ç¦ç”¨è§†é¢‘ï¼‰
try:
    import cv2  # noqa: F401
    CV2_OK = True
except Exception:
    CV2_OK = False

import skfuzzy as fuzz
from skfuzzy import control as ctrl
import time

st.set_page_config(page_title="YOLOç—…å®³æ£€æµ‹", page_icon="ğŸ§ª", layout="wide")

# ä»¥å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ä¸ºåŸºå‡†
BASE_DIR = Path(__file__).parent
WEIGHTS = BASE_DIR / "best.pt"
IMG_DIR = BASE_DIR / "img"
MODEL_PATHS = {"Lyc": str(WEIGHTS), "Ich": str(WEIGHTS), "Tomont": str(WEIGHTS)}


# ä½ çš„æ¨¡å‹æ¸…å•ï¼ˆå¯æ‰©å±•å¤šä¸ªï¼‰
# ========= æœ¬åœ°æ¨¡å‹ä¸å·¥å…· =========

# å¦‚æœä¸‰ä¸ªç±»åˆ«å…±ç”¨åŒä¸€æƒé‡ï¼Œå…ˆéƒ½æŒ‡å‘ best.ptï¼›å°†æ¥æœ‰ä¸åŒæƒé‡å†æ”¹è¿™é‡Œçš„è·¯å¾„å³å¯
# MODEL_PATHS = {"Lyc": "best.pt", "Ich": "best.pt", "Tomont": "best.pt"}

@st.cache_resource
def load_models():
    return {k: YOLO(p) for k, p in MODEL_PATHS.items()}

MODELS = load_models()

def detections_to_df(res) -> pd.DataFrame:
    """
    ç»Ÿä¸€è½¬è¡¨ï¼š
    - Ultralytics Resultsï¼ˆå•å¸§ï¼‰å¯¹è±¡ï¼šä» res.boxes æ cls/conf/xyxyã€‚
    - è€æ¥å£ list[dict]ï¼šç»§ç»­ä½¿ç”¨ d.get(...) å…¼å®¹ã€‚
    """
    # A) Ultralytics Results å¯¹è±¡
    if hasattr(res, "boxes") and hasattr(res, "names"):
        rows = []
        names = getattr(res, "names", {}) or {}
        boxes = getattr(res, "boxes", None)

        if boxes is not None and len(boxes) > 0:
            cls_np  = boxes.cls.detach().cpu().numpy().astype(int)
            conf_np = boxes.conf.detach().cpu().numpy()
            xyxy_np = boxes.xyxy.detach().cpu().numpy()
            for i in range(len(cls_np)):
                rows.append({
                    "category": names.get(int(cls_np[i]), str(int(cls_np[i]))),
                    "conf": float(conf_np[i]),
                    "location": [float(x) for x in xyxy_np[i].tolist()],
                })
        return pd.DataFrame(rows)

    # B) è€çš„ list[dict] ç»“æ„ï¼ˆä¿æŒå…¼å®¹ï¼Œå¦‚æœä½ ä¹‹åä¸ç”¨ï¼Œå¯ä»¥åˆ æ‰è¿™æ®µï¼‰
    if isinstance(res, list):
        rows = []
        for d in res or []:
            rows.append({
                "category": d.get("category") or d.get("class_name") or d.get("name") or d.get("cls"),
                "conf": d.get("conf") or d.get("confidence"),
                "location": d.get("location") or d.get("bbox") or d.get("xyxy"),
                "path": d.get("path"),
            })
        return pd.DataFrame(rows)

    # å·²æ˜¯ DataFrame ç›´æ¥è¿”å›ï¼›å…¶å®ƒç±»å‹ç»™ç©ºè¡¨
    if isinstance(res, pd.DataFrame):
        return res

    return pd.DataFrame()



def predict_on_image(img_input, model_key: str, conf: float):
    # ç»Ÿä¸€è½¬ PIL
    if isinstance(img_input, (bytes, bytearray)):
        pil_img = Image.open(io.BytesIO(img_input)).convert("RGB")
    elif isinstance(img_input, Image.Image):
        pil_img = img_input.convert("RGB")
    elif isinstance(img_input, (str, Path)):
        pil_img = Image.open(img_input).convert("RGB")
    elif isinstance(img_input, np.ndarray):
        if img_input.ndim == 2:
            pil_img = Image.fromarray(img_input)  # ç°åº¦
        elif img_input.ndim == 3:
            if CV2_OK:
                pil_img = Image.fromarray(cv2.cvtColor(img_input, cv2.COLOR_BGR2RGB))
            else:
                # å‡è®¾ BGR -> RGBï¼ˆæ—  cv2 æ—¶ç”¨é€šé“åè½¬ï¼‰
                pil_img = Image.fromarray(img_input[..., ::-1])
        else:
            raise TypeError(f"Unsupported numpy shape: {img_input.shape}")
    else:
        raise TypeError(f"Unsupported type: {type(img_input)}")

    # æ¨ç†
    r = MODELS[model_key].predict(source=pil_img, conf=float(conf), imgsz=640, verbose=False)[0]

    # å¯è§†åŒ–ï¼ˆUltralytics è¿”å› BGR ndarrayï¼‰
    im_bgr = r.plot()
    im_rgb = im_bgr[..., ::-1]  # ä¸ä¾èµ– cv2
    vis_pil = Image.fromarray(im_rgb)

    df = detections_to_df(r)
    return vis_pil, df



def process_video(video_bytes: bytes, model_key: str, conf: float, max_frames: int | None = None) -> Path:
    if not CV2_OK:
        raise RuntimeError("å½“å‰ç¯å¢ƒæœªèƒ½åŠ è½½ OpenCVï¼ˆcv2ï¼‰ï¼Œæ— æ³•è¿›è¡Œè§†é¢‘å¤„ç†ã€‚è¯·åœ¨æœ¬åœ°æˆ–æ”¯æŒ OpenCV çš„ç¯å¢ƒè¿è¡Œè¯¥åŠŸèƒ½ã€‚")
    """é€å¸§æ¨ç†å¹¶è¾“å‡º mp4ï¼Œè¿”å›è¾“å‡ºè§†é¢‘è·¯å¾„"""
    in_path = Path("input_tmp.mp4"); in_path.write_bytes(video_bytes)
    cap = cv2.VideoCapture(str(in_path))
    if not cap.isOpened(): raise RuntimeError("æ— æ³•è¯»å–è§†é¢‘")

    fps = cap.get(cv2.CAP_PROP_FPS) or 25
    w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out_path = Path(f"processed_{int(time.time())}.mp4")
    vw = cv2.VideoWriter(str(out_path), cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))

    i = 0
    while True:
        ok, frame = cap.read()
        if not ok: break
        i += 1
        if max_frames and i > max_frames: break
        r = MODELS[model_key].predict(source=frame, conf=float(conf), imgsz=640, verbose=False)[0]
        vw.write(r.plot())

    cap.release(); vw.release()
    return out_path

def save_table_to_excel(df: pd.DataFrame, filename: str) -> Path:
    out = Path(filename).with_suffix(".xlsx")
    with pd.ExcelWriter(out, engine="xlsxwriter") as w:
        df.to_excel(w, sheet_name="detections", index=False)
    return out

def zip_files(files: list[Path], out_zip: Path) -> Path:
    with zipfile.ZipFile(out_zip, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for f in files:
            if f.exists(): zf.write(f, arcname=f.name)
    return out_zip

# ========= æ¨¡ç³Šé¢„æµ‹ï¼ˆå’Œä½ åç«¯ä¸€è‡´çš„ scikit-fuzzy è§„åˆ™ï¼‰ =========
@st.cache_resource
def build_fuzzy_sim():
    day = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'day')
    night = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'night')
    surf = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'surf')
    patho = ctrl.Antecedent(np.arange(1, 4.1, 0.1), 'patho')
    risk = ctrl.Consequent(np.arange(0, 4.1, 0.1), 'risk')

    for b in [day, night]:
        b['healthy'] = fuzz.trimf(b.universe, [1, 1, 1.5])
        b['subhealthy'] = fuzz.trimf(b.universe, [1.5, 2, 2.5])
        b['diseased'] = fuzz.trimf(b.universe, [2.5, 3, 4])

    surf['healthy'] = fuzz.trimf(surf.universe, [1, 1, 2])
    surf['diseased'] = fuzz.trimf(surf.universe, [2, 3, 4])
    patho['absent'] = fuzz.trimf(patho.universe, [1, 1, 2])
    patho['present'] = fuzz.trimf(patho.universe, [2, 3, 4])

    risk['health'] = fuzz.trimf(risk.universe, [0, 1, 1.5])
    risk['subhealth'] = fuzz.trimf(risk.universe, [1.5, 2, 2.5])
    risk['diseased'] = fuzz.trimf(risk.universe, [2.5, 3, 4])
    risk.defuzzify_method = 'centroid'

    rules = [
        ctrl.Rule(day['subhealthy'] & night['diseased'] & surf['healthy'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['healthy'] & patho['absent'], risk['health']),
        ctrl.Rule(day['diseased'] | night['diseased'], risk['diseased']),
        ctrl.Rule(day['subhealthy'] | night['subhealthy'], risk['subhealth']),
        ctrl.Rule(surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(surf['healthy'] & patho['absent'], risk['health']),
        ctrl.Rule(day['healthy'] & night['subhealthy'] & surf['healthy'] & patho['present'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['healthy'] & surf['healthy'] & patho['present'], risk['subhealth']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['healthy'] & patho['present'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['healthy'] & patho['absent'], risk['health']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['diseased'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['subhealthy'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['diseased'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['healthy'] & night['subhealthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['healthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['subhealthy'] & night['subhealthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['healthy'] & night['healthy'] & surf['diseased'] & patho['absent'], risk['subhealth']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['healthy'] & patho['absent'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['diseased'] & patho['absent'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['healthy'] & patho['present'], risk['diseased']),
        ctrl.Rule(day['diseased'] & night['diseased'] & surf['diseased'] & patho['present'], risk['diseased']),
    ]
    for r in rules: r.weight = 1.0
    rules[4].weight = 2; rules[5].weight = 2

    return ctrl.ControlSystemSimulation(ctrl.ControlSystem(rules))

def fuzzy_predict(day_val: float, night_val: float, surf_val: float, patho_val: float) -> dict:
    sim = build_fuzzy_sim()
    sim.input['day'] = day_val
    sim.input['night'] = night_val
    sim.input['surf'] = surf_val
    sim.input['patho'] = patho_val
    sim.compute()
    v = float(sim.output['risk'])
    status = "å¥åº·" if v < 1.5 else ("äºšå¥åº·" if v < 2.5 else "æ‚£ç—…")
    return {"risk_value": round(v, 1), "risk_status": status}


# ========================= å…¨å±€è®¾ç½® & ä¸»é¢˜æ‰©å±• =========================


# ç»Ÿä¸€çš„ CSSï¼šå¯¼èˆªæ¡ / å¡ç‰‡ / æ ‡ç­¾ / è¡¨æ ¼ / æŒ‰é’®
st.markdown("""
<style>
.app-header {
  background: linear-gradient(90deg, #4F46E5 0%, #7C3AED 100%);
  color: white; border-radius: 16px; padding: 16px 20px; margin-bottom: 12px;
  display:flex; align-items:center; gap:14px;
}
.app-title { font-size: 22px; font-weight: 700; letter-spacing:.3px; }
.app-subtitle { opacity:.9; font-size: 13px; }

.note {
  background:#EEF2FF; border:1px solid #E0E7FF; color:#3730A3;
  border-radius: 12px; padding: 10px 12px; margin: 6px 0 16px 0; font-size:13px;
}

.card {
  background: var(--secondary-bg, #F6F7FB);
  border: 1px solid #E5E7EB;
  border-radius: 14px;
  padding: 14px;
  margin-bottom: 12px;
}

:root { --secondary-bg: #F6F7FB; }
[data-base-theme="light"] :root { --secondary-bg: #F6F7FB; }
[data-base-theme="dark"]  :root { --secondary-bg: #111827; }

[data-testid="stDataFrame"] { border-radius: 12px; overflow:hidden; }

.stButton>button { border-radius: 10px; }
.block-container { padding-top: 0.6rem; padding-bottom: 1rem; }

.badge {
  display: inline-flex; align-items: center; gap: 6px;
  background: #EEF2FF; color:#3730A3; border:1px solid #E0E7FF;
  padding: 4px 8px; border-radius: 999px; font-size: 12px; font-weight:600;
}
</style>
""", unsafe_allow_html=True)

# éšè— Streamlit é¡¶éƒ¨æ ï¼ˆæ–¹æ¡ˆ Bï¼‰
st.markdown("""
<style>
header[data-testid="stHeader"] {visibility: hidden;}
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
[data-testid="stAppViewContainer"] .main .block-container { padding-top: 0.8rem !important; }
.app-header { margin-top: 4px; }
</style>
""", unsafe_allow_html=True)

# åªéšè—æˆ‘ä»¬è‡ªå®šä¹‰çš„æœåŠ¡é…ç½®å®¹å™¨ï¼ˆæ›´ç¨³ï¼‰
st.markdown("""
<style>
#svc-config { display: none !important; }  /* â† è¢«éšè—çš„å®¹å™¨ */
</style>
""", unsafe_allow_html=True)

# é¡¶éƒ¨å¯¼èˆªæ¡
st.markdown("""
<style>
/* ===== é¡¶éƒ¨æ¨ªå¹…æ•´ä½“æ ·å¼ ===== */
.app-header {
  background: linear-gradient(90deg, #4F46E5 0%, #7C3AED 100%);
  color: white;
  border-radius: 14px;     /* åœ†è§’ç¨å¾®å°ä¸€äº› */
  padding: 14px 18px;      /* åŸæ¥ 26x20ï¼Œç¼©å°åˆ°æ›´ç´§å‡‘ */
  margin-bottom: 14px;
  text-align: center;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
}


/* ===== å›¾æ ‡ä¸æ ‡é¢˜ä¸€è¡Œ ===== */
.app-title-row {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 12px;  /* å›¾æ ‡ä¸æ ‡é¢˜é—´è· */
  margin-bottom: 8px;
}

.app-icon {
  font-size: 42px;
}

.app-title {
  font-size: 36px;
  font-weight: 800;
  letter-spacing: 1px;
}

.app-subtitle {
  font-size: 20px;
  opacity: 0.95;
}
</style>

<div class="app-header">
  <div class="app-title-row">
    <div class="app-icon">ğŸ§ª</div>
    <div class="app-title">YOLOå¯„ç”Ÿè™«æ£€æµ‹</div>
  </div>
  <div class="app-subtitle">å›¾ç‰‡ / æ‰¹é‡ / è§†é¢‘ / æ‘„åƒå¤´ / æ¨¡ç³Šé¢„æµ‹ â€” ä¸€ç«™å¼æ£€æµ‹å°</div>
</div>
""", unsafe_allow_html=True)



# ------------------------- ä¾§è¾¹æ  -------------------------
with st.sidebar:
    # ======= è¿™é‡Œæ”¾ä½ çš„æ ¡å¾½ / é¡¹ç›®ç®€ä»‹ï¼ˆä¼šæ˜¾ç¤ºï¼‰=======
    # æŠŠ school_logo.png æ”¾åˆ°åŒçº§ç›®å½•åå–æ¶ˆä¸‹ä¸€è¡Œæ³¨é‡Šå³å¯ï¼š
    # st.image("school_logo.png", use_container_width=True)
    st.markdown("""
    ### ğŸ“ å®æ³¢å¤§å­¦ Â· ç—…å®³å®éªŒå®¤
    """)
    # st.image("img/img1.png", width='stretch')
    st.image(str(IMG_DIR / "img1.png"), use_container_width=True)

    # st.markdown("---")
    # ======= ä»¥ä¸‹ä¸ºâ€œæœåŠ¡é…ç½® + æ¨¡å‹å‚æ•°â€åŒºåŸŸï¼Œå¤–é¢åŒ…äº†ä¸€ä¸ªå®¹å™¨ï¼Œå·²é€šè¿‡ CSS éšè— =======
    st.markdown('<div id="svc-config">', unsafe_allow_html=True)

    # st.header("âš™ï¸ æœåŠ¡é…ç½®")
    # base_url = st.text_input("åç«¯åœ°å€", value="http://localhost:8080",
    #                          help="ç¤ºä¾‹ï¼šhttp://127.0.0.1:8000 æˆ– http://localhost:8080")
    # default_ws = base_url.replace("http://", "ws://").replace("https://", "wss://")
    # ws_url_override = st.text_input("WebSocket åŸºåœ°å€ï¼ˆå¯é€‰ï¼‰", value=default_ws,
    #                                 help="é€šå¸¸ä¸åç«¯ä¸€è‡´ï¼Œè‡ªåŠ¨ä»åç«¯åœ°å€æ¨å¯¼")

    base_url = "http://localhost:8080"
    ws_url_override = base_url.replace("http://", "ws://").replace("https://", "wss://")
    st.divider()
    st.header("ğŸ§  æ¨¡å‹ä¸å‚æ•°")
    model_options = {"Lyc": "åˆºæ¿€éšæ ¸è™«", "Ich": "å¤šå­å°ç“œè™«", "Tomont": "åŒ…å›Š"}
    model_value = st.selectbox("æ¨¡å‹ç±»å‹", options=list(model_options.keys()),
                               format_func=lambda x: f"{x}ï¼ˆ{model_options[x]}ï¼‰")
    conf = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆè‹¥åç«¯æ”¯æŒï¼‰", 0.05, 0.9, 0.25, 0.05)
    st.markdown(f"<span class='badge'>å½“å‰æ¨¡å‹: <b>{model_value}</b></span>", unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)  # â† ç»“æŸéšè—å®¹å™¨

# # é¡¶éƒ¨æç¤ºæ¡
# st.markdown("""
# <div class="note">
# ğŸ’¡ å°æç¤ºï¼šå·¦ä¾§å¯å±•ç¤ºæ ¡å¾½ä¸é¡¹ç›®ç®€ä»‹ï¼›å†…éƒ¨â€œæœåŠ¡é…ç½®/æ¨¡å‹å‚æ•°â€å·²éšè—ä½†ä»ç”Ÿæ•ˆã€‚å¦‚éœ€ä¸´æ—¶æ˜¾ç¤ºï¼Œå¯æŠŠ CSS ä¸­çš„ #svc-config éšè—è§„åˆ™å»æ‰ã€‚
# </div>
# """, unsafe_allow_html=True)

# ========================= å·¥å…·å‡½æ•° =========================
def b64_to_pil(maybe_b64):
    """å…¼å®¹çº¯ base64 / data URL / bytesï¼›URL è¿”å› None äº¤ç”± st.image(url)ã€‚"""
    import io, base64
    from PIL import Image
    if maybe_b64 is None:
        raise ValueError("empty image input")
    if isinstance(maybe_b64, str) and maybe_b64.strip().lower().startswith(("http://", "https://")):
        return None
    if isinstance(maybe_b64, (bytes, bytearray)):
        return Image.open(io.BytesIO(maybe_b64)).convert("RGB")
    if isinstance(maybe_b64, str):
        s = maybe_b64.strip()
        if s.lower().startswith("data:image"):
            parts = s.split(",", 1)
            s = parts[1] if len(parts) > 1 else ""
        s = s.replace("\n", "").replace("\r", "").replace(" ", "")
        missing = len(s) % 4
        if missing:
            s += "=" * (4 - missing)
        raw = base64.b64decode(s, validate=False)
        return Image.open(io.BytesIO(raw)).convert("RGB")
    raise TypeError(f"unsupported type for image: {type(maybe_b64)}")

def ensure_ok(resp: requests.Response):
    if not resp.ok:
        try:
            detail = resp.json()
        except Exception:
            detail = resp.text
        raise RuntimeError(f"HTTP {resp.status_code}: {detail}")

def save_table_to_excel(df: pd.DataFrame, filename: str) -> Path:
    out = Path(filename).with_suffix(".xlsx")
    with pd.ExcelWriter(out, engine="xlsxwriter") as writer:
        df.to_excel(writer, sheet_name="detections", index=False)
    return out

def zip_files(files: List[Path], out_zip: Path) -> Path:
    with zipfile.ZipFile(out_zip, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for f in files:
            if f.exists():
                zf.write(f, arcname=f.name)
    return out_zip

# ========================= æ ‡ç­¾é¡µ =========================
tab_img, tab_folder, tab_video, tab_camera, tab_fuzzy = st.tabs(
    ["ğŸ–¼ï¸ å›¾ç‰‡æ£€æµ‹", "ğŸ—‚ï¸ æ‰¹é‡å›¾ç‰‡", "ğŸï¸ è§†é¢‘æ£€æµ‹", "ğŸ“· æ‘„åƒå¤´æ£€æµ‹", "ğŸ§® æ¨¡ç³Šé¢„æµ‹"]
)

# -------------------------------- 1) å›¾ç‰‡æ£€æµ‹ --------------------------------
with tab_img:
    st.markdown("#### ğŸ–¼ï¸ å›¾ç‰‡æ£€æµ‹")
    col1, col2 = st.columns(2)

    # å·¦ä¾§ï¼šåŸå›¾
    with col1:
        st.markdown("<div class='card'><b>åŸå›¾</b></div>", unsafe_allow_html=True)
        img_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["jpg","jpeg","png","bmp","webp"], key="single_img_main")
        if img_file:
            st.image(Image.open(img_file), caption="åŸå›¾", width='stretch')

    # å³ä¾§ï¼šæ£€æµ‹ä¸ç»“æœ
    with col2:
        st.markdown("<div class='card'><b>æ£€æµ‹ä¸ç»“æœ</b></div>", unsafe_allow_html=True)
        run_single = st.button("ğŸš€ å¼€å§‹æ£€æµ‹", type="primary", use_container_width=True, disabled=img_file is None)

        if run_single and img_file:
            files = {"file": (img_file.name, img_file.getvalue(), img_file.type or "image/jpeg")}
            data = {"model_type": model_value}
            params = {"conf": conf}

            with st.spinner("æœ¬åœ°æ¨¡å‹æ¨ç†ä¸­..."):
                det_img, df = predict_on_image(img_file.getvalue(), model_value, conf)

            st.image(det_img, caption="æ£€æµ‹ç»“æœ", width='stretch')
            if not df.empty:
                st.dataframe(df, use_container_width=True)
                c1, c2 = st.columns(2)
                with c1:
                    if st.button("ä¸‹è½½ Excelï¼ˆæ£€æµ‹è¡¨ï¼‰", use_container_width=True):
                        xlsx_path = save_table_to_excel(df, "image_detect_result.xlsx")
                        st.download_button("ç‚¹å‡»ä¸‹è½½", data=open(xlsx_path, "rb").read(),
                                           file_name=xlsx_path.name,
                                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                with c2:
                    if st.button("ä¸‹è½½ æ ‡æ³¨å›¾ç‰‡", use_container_width=True):
                        bio = io.BytesIO();
                        det_img.save(bio, format="JPEG")
                        st.download_button("ç‚¹å‡»ä¸‹è½½", data=bio.getvalue(), file_name="image_detect_result.jpg",
                                           mime="image/jpeg")

# ----------------------------- 2) æ‰¹é‡å›¾ç‰‡æ£€æµ‹ -----------------------------
with tab_folder:
    st.markdown("#### ğŸ—‚ï¸ æ‰¹é‡å›¾ç‰‡æ£€æµ‹")
    files = st.file_uploader(
        "é€‰æ‹©å¤šå¼ å›¾ç‰‡",
        type=["jpg", "jpeg", "png", "bmp", "webp"],
        accept_multiple_files=True,
        key="multi_imgs",
    )
    go = st.button("ğŸš€ å¼€å§‹æ‰¹é‡æ£€æµ‹", type="primary", disabled=not files)

    if go and files:
        all_tables: List[pd.DataFrame] = []
        out_imgs: List[Path] = []

        progress = st.progress(0)
        status = st.empty()

        total = len(files)
        for i, f in enumerate(files, start=1):
            status.info(f"æ¨ç†ä¸­ï¼š{f.name} ({i}/{total})")
            with st.spinner(f"æ¨ç†ï¼š{f.name}"):
                det_img, df = predict_on_image(f.getvalue(), model_value, conf)

                # ç»“æœè¡¨
                if not df.empty:
                    df["path"] = f.name
                    all_tables.append(df)

                # ä¿å­˜æ ‡æ³¨å›¾åˆ°æœ¬åœ°ï¼Œç¨åæ‰“åŒ…ä¸‹è½½
                out_path = Path(f"{Path(f.name).stem}_detect.jpg")
                det_img.save(out_path)
                out_imgs.append(out_path)

            progress.progress(i / total)

        # æ±‡æ€»è¡¨æ ¼
        df_all = pd.concat(all_tables, ignore_index=True) if all_tables else pd.DataFrame()
        if not df_all.empty:
            st.dataframe(df_all, use_container_width=True)
            xlsx_path = save_table_to_excel(df_all, "batch_detect.xlsx")
            st.download_button(
                "ğŸ“¥ ä¸‹è½½ Excelï¼ˆæ‰¹é‡æ£€æµ‹è¡¨ï¼‰",
                data=open(xlsx_path, "rb").read(),
                file_name=xlsx_path.name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
        else:
            st.info("æœªæ£€æµ‹åˆ°ç›®æ ‡ã€‚")

        # æ‰“åŒ…æ ‡æ³¨å›¾
        if out_imgs:
            zpath = zip_files(out_imgs, Path("batch_detect_images.zip"))
            st.download_button(
                "ğŸ—œï¸ æ‰“åŒ…ä¸‹è½½ æ ‡æ³¨å›¾ç‰‡ZIP",
                data=open(zpath, "rb").read(),
                file_name=zpath.name,
                mime="application/zip",
                use_container_width=True,
            )

        status.empty()
        progress.empty()


# -------------------------------- 3) è§†é¢‘æ£€æµ‹ --------------------------------
# -------------------------------- 3) è§†é¢‘æ£€æµ‹ --------------------------------
with tab_video:
    st.markdown("#### ğŸï¸ è§†é¢‘æ£€æµ‹")
    vid_file = st.file_uploader(
        "ä¸Šä¼ è§†é¢‘", type=["mp4", "mov", "avi", "mkv"], key="video_file"
    )
    # run_vid = st.button("ğŸš€ å¼€å§‹è§†é¢‘æ£€æµ‹", type="primary", disabled=vid_file is None)
    run_vid = st.button("ğŸš€ å¼€å§‹è§†é¢‘æ£€æµ‹", type="primary", disabled=(vid_file is None or not CV2_OK))
    if not CV2_OK:
        st.warning("å½“å‰äº‘ç«¯ç¯å¢ƒæœªèƒ½åŠ è½½ OpenCVï¼ˆcv2ï¼‰ï¼Œè§†é¢‘å¤„ç†åŠŸèƒ½å·²ç¦ç”¨ã€‚è¯·åœ¨æœ¬åœ°è¿è¡Œæˆ–å®‰è£…æ”¯æŒçš„ OpenCV ç‰ˆæœ¬ã€‚")

    if run_vid and vid_file:
        with st.spinner("æœ¬åœ°è§†é¢‘å¤„ç†...ï¼ˆæŒ‰ CPU é€Ÿåº¦å¯èƒ½è¾ƒæ…¢ï¼‰"):
            # æœ¬åœ°é€å¸§æ¨ç†å¹¶å¯¼å‡ºå¤„ç†åçš„è§†é¢‘
            out_path = process_video(
                vid_file.getvalue(), model_value, conf, max_frames=None
            )
        st.video(str(out_path))
        st.download_button(
            "ä¸‹è½½å¤„ç†åè§†é¢‘",
            data=open(out_path, "rb").read(),
            file_name=out_path.name,
            mime="video/mp4",
        )


# -------------------------- 4) æ‘„åƒå¤´æ£€æµ‹ï¼ˆWebSocketï¼‰ --------------------------
# -------------------------- 4) æ‘„åƒå¤´æ£€æµ‹ï¼ˆæ‹ç…§ç‰ˆï¼Œæ‰‹åŠ¨å¼€å¯ï¼‰ --------------------------
with tab_camera:
    st.markdown("#### ğŸ“· æ‘„åƒå¤´æ£€æµ‹ï¼ˆæ‹ç…§ç‰ˆï¼‰")
    st.caption("ç‚¹å‡»â€œæ‰“å¼€æ‘„åƒå¤´â€åæ‰æ¸²æŸ“æ‹ç…§æ§ä»¶ï¼›ç‚¹å‡»â€œå…³é—­æ‘„åƒå¤´â€åœæ­¢å¹¶éšè—ã€‚")

    # åˆå§‹åŒ–çŠ¶æ€
    if "cam_on" not in st.session_state:
        st.session_state.cam_on = False

    col_a, col_b = st.columns(2)
    if not st.session_state.cam_on:
        if col_a.button("ğŸ¬ æ‰“å¼€æ‘„åƒå¤´", type="primary"):
            st.session_state.cam_on = True
            st.rerun()
        col_b.button("â¹ å…³é—­æ‘„åƒå¤´", disabled=True)
        st.info("æ‘„åƒå¤´æœªå¼€å¯ã€‚ç‚¹å‡»â€œæ‰“å¼€æ‘„åƒå¤´â€å¼€å§‹æ‹ç…§ã€‚")
    else:
        if col_b.button("â¹ å…³é—­æ‘„åƒå¤´", type="secondary"):
            st.session_state.cam_on = False
            st.rerun()
        col_a.button("ğŸ¬ æ‰“å¼€æ‘„åƒå¤´", disabled=True)

        # åªæœ‰åœ¨ cam_on=True æ—¶æ‰æ¸²æŸ“ camera_inputï¼Œé¿å…é¡µé¢åŠ è½½å°±è§¦å‘æƒé™ä¸å–æµ
        snap = st.camera_input("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æ‹ä¸€å¼ ", key="cam_shot")

        go = st.button("æ£€æµ‹æ­¤ç…§ç‰‡", type="primary", disabled=(snap is None))
        if go and snap is not None:
            with st.spinner("æœ¬åœ°æ¨¡å‹æ¨ç†ä¸­..."):
                det_img, df = predict_on_image(snap.getvalue(), model_value, conf)
            st.image(det_img, caption="æ£€æµ‹ç»“æœ", use_container_width=True)
            if not df.empty:
                st.dataframe(df, use_container_width=True)

# -------------------------------- 5) æ¨¡ç³Šé¢„æµ‹ --------------------------------
with tab_fuzzy:
    st.markdown("#### ğŸ§® æ¨¡ç³Šé¢„æµ‹")
    st.markdown("<div class='card'><b>è¾“å…¥æŒ‡æ ‡å‚æ•°</b></div>", unsafe_allow_html=True)

    c1, c2 = st.columns(2)
    with c1:
        day_behavior   = st.number_input("æ—¥é—´è¡Œä¸ºï¼ˆ1~4ï¼‰",  min_value=1.0, max_value=4.0, value=2.0, step=0.1)
        night_behavior = st.number_input("å¤œé—´è¡Œä¸ºï¼ˆ1~4ï¼‰",  min_value=1.0, max_value=4.0, value=2.4, step=0.1)
    with c2:
        surface_features = st.number_input("ä½“è¡¨ç‰¹å¾ï¼ˆ1~4ï¼‰", min_value=1.0, max_value=4.0, value=1.8, step=0.1)
        pathogen         = st.number_input("ç—…åŸç‰¹å¾ï¼ˆ1~4ï¼‰", min_value=1.0, max_value=4.0, value=2.6, step=0.1)

    if st.button("ğŸ§ª é¢„æµ‹", type="primary"):
        r = fuzzy_predict(day_behavior, night_behavior, surface_features, pathogen)
        st.success(f"é£é™©å€¼: {r['risk_value']}ï¼ŒçŠ¶æ€: {r['risk_status']}")




